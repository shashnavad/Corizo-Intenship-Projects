{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_data = pd.read_csv('/Users/prathamgupta/Desktop/trainingLabeled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a62ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top100Year</th>\n",
       "      <th>SongTitle</th>\n",
       "      <th>Artist</th>\n",
       "      <th>LyricsStatus</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>ReleaseYear</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>West Coast</td>\n",
       "      <td>Lana Del Rey</td>\n",
       "      <td>True</td>\n",
       "      <td>I can see my baby swingin'\\nOoh baby baby bae,...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Soft rock, Alternative/Indie, Pop</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>Miranda Lambert</td>\n",
       "      <td>True</td>\n",
       "      <td>Quarter in a payphone\\nDrying laundry on the l...</td>\n",
       "      <td>2015</td>\n",
       "      <td>Alternative/Indie, Pop</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>Bartender</td>\n",
       "      <td>Lady Antebellum</td>\n",
       "      <td>True</td>\n",
       "      <td>8 o'clock on Friday night I'm still at home\\nA...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Country music, House music, Dance/Electronic, ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>Beat Of The Music</td>\n",
       "      <td>Brett Eldredge</td>\n",
       "      <td>True</td>\n",
       "      <td>Well, I just met you a couple hours ago\\nMy la...</td>\n",
       "      <td>2013</td>\n",
       "      <td>Pop, UK R&amp;B, Hip-Hop/Rap, Rock</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Habits (Stay High)</td>\n",
       "      <td>Tove Lo</td>\n",
       "      <td>True</td>\n",
       "      <td>I eat my dinner in my bathtub\\nThen I go to se...</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pop music, Electropop, Latin Urbano, Alternati...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2023</td>\n",
       "      <td>Jaded</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>True</td>\n",
       "      <td>I don't wanna call and talk too long\\nI know i...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Dirty rap, R&amp;B/Soul, Afroswing, Hip-Hop/Rap, U...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2023</td>\n",
       "      <td>Boy's A Liar, Pt. 2</td>\n",
       "      <td>PinkPantheress &amp; Ice Spice</td>\n",
       "      <td>True</td>\n",
       "      <td>Take a look inside your heart, is there any ro...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Rap music, Alternative/Indie, Pop, UK R&amp;B, UK Rap</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2023</td>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td>True</td>\n",
       "      <td>I'll touch that fire for you\\nI do that three,...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Synth-pop, Pop rock, Pop</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2023</td>\n",
       "      <td>Need A Favor</td>\n",
       "      <td>Jelly Roll</td>\n",
       "      <td>True</td>\n",
       "      <td>I only talk to God when I need a favor\\nAnd I ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Electropop, Country</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>2023</td>\n",
       "      <td>Area Codes</td>\n",
       "      <td>Kaliii</td>\n",
       "      <td>True</td>\n",
       "      <td>Yeah, yeah (28Shit)\\nKali\\nYou know I love me ...</td>\n",
       "      <td>2022</td>\n",
       "      <td>Rap music, Alternative/Indie, Pop, UK R&amp;B, UK Rap</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>642 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Top100Year            SongTitle                      Artist  \\\n",
       "0          2014           West Coast                Lana Del Rey   \n",
       "1          2014            Automatic             Miranda Lambert   \n",
       "2          2014            Bartender             Lady Antebellum   \n",
       "3          2014    Beat Of The Music              Brett Eldredge   \n",
       "4          2014   Habits (Stay High)                     Tove Lo   \n",
       "..          ...                  ...                         ...   \n",
       "637        2023                Jaded                 Miley Cyrus   \n",
       "638        2023  Boy's A Liar, Pt. 2  PinkPantheress & Ice Spice   \n",
       "639        2023               Snooze                         SZA   \n",
       "640        2023         Need A Favor                  Jelly Roll   \n",
       "641        2023           Area Codes                      Kaliii   \n",
       "\n",
       "     LyricsStatus                                             Lyrics  \\\n",
       "0            True  I can see my baby swingin'\\nOoh baby baby bae,...   \n",
       "1            True  Quarter in a payphone\\nDrying laundry on the l...   \n",
       "2            True  8 o'clock on Friday night I'm still at home\\nA...   \n",
       "3            True  Well, I just met you a couple hours ago\\nMy la...   \n",
       "4            True  I eat my dinner in my bathtub\\nThen I go to se...   \n",
       "..            ...                                                ...   \n",
       "637          True  I don't wanna call and talk too long\\nI know i...   \n",
       "638          True  Take a look inside your heart, is there any ro...   \n",
       "639          True  I'll touch that fire for you\\nI do that three,...   \n",
       "640          True  I only talk to God when I need a favor\\nAnd I ...   \n",
       "641          True  Yeah, yeah (28Shit)\\nKali\\nYou know I love me ...   \n",
       "\n",
       "    ReleaseYear                                              Genre     Label  \n",
       "0          2014                  Soft rock, Alternative/Indie, Pop  Positive  \n",
       "1          2015                             Alternative/Indie, Pop  Positive  \n",
       "2          2014  Country music, House music, Dance/Electronic, ...  Positive  \n",
       "3          2013                     Pop, UK R&B, Hip-Hop/Rap, Rock  Positive  \n",
       "4          2014  Pop music, Electropop, Latin Urbano, Alternati...  Negative  \n",
       "..          ...                                                ...       ...  \n",
       "637        2023  Dirty rap, R&B/Soul, Afroswing, Hip-Hop/Rap, U...  Negative  \n",
       "638        2023  Rap music, Alternative/Indie, Pop, UK R&B, UK Rap  Positive  \n",
       "639        2022                           Synth-pop, Pop rock, Pop  Positive  \n",
       "640        2023                                Electropop, Country  Positive  \n",
       "641        2022  Rap music, Alternative/Indie, Pop, UK R&B, UK Rap  Positive  \n",
       "\n",
       "[642 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2d4e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"What would I do without your smart mouth?\\nDrawing me in, and you kicking me out\\nYou've got my head spinning, no kidding, I can't pin you down\\nWhat's going on in that beautiful mind?\\nI'm on your magical mystery ride\\nAnd I'm so dizzy, don't know what hit me, but I'll be alright\\nMy head's under water\\nBut I'm breathing fine\\nYou're crazy and I'm out of my mind\\n'Cause all of me\\nLoves all of you\\nLove your curves and all your edges\\nAll your perfect imperfections\\nGive your all to me\\nI'll give my all to you\\nYou're my end and my beginning\\nEven when I lose, I'm winning\\n'Cause I give you all of me\\nAnd you give me all of you, oh-oh\\nHow many times do I have to tell you?\\nEven when you're crying, you're beautiful too\\nThe world is beating you down, I'm around through every mood\\nYou're my downfall, you're my muse\\nMy worst distraction, my rhythm and blues\\nI can't stop singing, it's ringing in my head for you\\nMy head's under water\\nBut I'm breathing fine\\nYou're crazy and I'm out of my mind\\n'Cause all of me\\nLoves all of you\\nLove your curves and all your edges\\nAll your perfect imperfections\\nGive your all to me\\nI'll give my all to you\\nYou're my end and my beginning\\nEven when I lose, I'm winning\\n'Cause I give you all of me\\nAnd you give me all of you, oh-oh\\nGive me all of you, oh\\nCards on the table, we're both showing hearts\\nRisking it all, though it's hard\\n'Cause all of me\\nLoves all of you\\nLove your curves and all your edges\\nAll your perfect imperfections\\nGive your all to me\\nI'll give my all to you\\nYou're my end and my beginning\\nEven when I lose, I'm winning\\n'Cause I give you all of me\\nAnd you give me all of you\\nI give you all of me\\nAnd you give me all of you, oh-oh\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3fdc56bf8af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[1;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    795\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    796\u001b[0m         \"\"\"\n\u001b[0;32m--> 797\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/arrays/numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"What would I do without your smart mouth?\\nDrawing me in, and you kicking me out\\nYou've got my head spinning, no kidding, I can't pin you down\\nWhat's going on in that beautiful mind?\\nI'm on your magical mystery ride\\nAnd I'm so dizzy, don't know what hit me, but I'll be alright\\nMy head's under water\\nBut I'm breathing fine\\nYou're crazy and I'm out of my mind\\n'Cause all of me\\nLoves all of you\\nLove your curves and all your edges\\nAll your perfect imperfections\\nGive your all to me\\nI'll give my all to you\\nYou're my end and my beginning\\nEven when I lose, I'm winning\\n'Cause I give you all of me\\nAnd you give me all of you, oh-oh\\nHow many times do I have to tell you?\\nEven when you're crying, you're beautiful too\\nThe world is beating you down, I'm around through every mood\\nYou're my downfall, you're my muse\\nMy worst distraction, my rhythm and blues\\nI can't stop singing, it's ringing in my head for you\\nMy head's under water\\nBut I'm breathing fine\\nYou're crazy and I'm out of my mind\\n'Cause all of me\\nLoves all of you\\nLove your curves and all your edges\\nAll your perfect imperfections\\nGive your all to me\\nI'll give my all to you\\nYou're my end and my beginning\\nEven when I lose, I'm winning\\n'Cause I give you all of me\\nAnd you give me all of you, oh-oh\\nGive me all of you, oh\\nCards on the table, we're both showing hearts\\nRisking it all, though it's hard\\n'Cause all of me\\nLoves all of you\\nLove your curves and all your edges\\nAll your perfect imperfections\\nGive your all to me\\nI'll give my all to you\\nYou're my end and my beginning\\nEven when I lose, I'm winning\\n'Cause I give you all of me\\nAnd you give me all of you\\nI give you all of me\\nAnd you give me all of you, oh-oh\""
     ]
    }
   ],
   "source": [
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(lyrics_data[\"Lyrics\"], lyrics_data[\"Label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# model = LogisticRegression()\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1cfddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_lyrics = \"The sky is blue, the grass is green, and I'm feeling good.\"\n",
    "# sentiment_prediction = model.predict(new_lyrics)\n",
    "# print(sentiment_prediction)  # Output: ['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d911c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'mediapipe.python.solutions' has no attribute 'sentiment_analysis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c5ed0e6c0462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a Medapipe Graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment_analysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Process the Text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.python.solutions' has no attribute 'sentiment_analysis'"
     ]
    }
   ],
   "source": [
    "text = lyrics_data[\"Lyrics\"]  # Replace \"lyrics\" with the name of the column containing lyrics in your CSV file\n",
    "\n",
    "# Create a Medapipe Graph\n",
    "graph = mp.solutions.sentiment_analysis.Graph()\n",
    "\n",
    "# Process the Text\n",
    "results = []\n",
    "for i in text:\n",
    "  # Convert text to a single string\n",
    "  processed_text = \" \".join(i.split())\n",
    "\n",
    "  # Run the graph on the processed text\n",
    "  outputs = graph.process(mp.solutions.sentiment_analysis.ProcessRequest(input_text=processed_text))\n",
    "\n",
    "  # Extract sentiment score and label\n",
    "  sentiment_score = outputs.sentiment_score\n",
    "  sentiment_label = outputs.sentiment_label\n",
    "\n",
    "  # Create a dictionary for each item\n",
    "  item_results = {\"lyrics\": i, \"sentiment_score\": sentiment_score, \"sentiment_label\": sentiment_label}\n",
    "\n",
    "  # Append the results to a list\n",
    "  results.append(item_results)\n",
    "\n",
    "# Print the results\n",
    "print(results)\n",
    "\n",
    "# You can now analyze the sentiment score and label for each item in the CSV file\n",
    "print(\"Sentiment Score:\")\n",
    "print([item[\"sentiment_score\"] for item in results])\n",
    "\n",
    "print(\"Sentiment Label:\")\n",
    "print([item[\"sentiment_label\"] for item in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0840017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 5.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.2.4\n",
      "    Uninstalling pip-20.2.4:\n",
      "      Successfully uninstalled pip-20.2.4\n",
      "Successfully installed pip-24.0\n",
      "Collecting mediapipe-model-maker\n",
      "  Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe-model-maker) (2.1.0)\n",
      "INFO: pip is looking at multiple versions of mediapipe-model-maker to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading mediapipe_model_maker-0.2.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading mediapipe_model_maker-0.2.1.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading mediapipe_model_maker-0.2.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Downloading mediapipe_model_maker-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading mediapipe_model_maker-0.1.1.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading mediapipe_model_maker-0.1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "  Downloading mediapipe_model_maker-0.1.0.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mediapipe==0.9.0.1 (from mediapipe-model-maker)\n",
      "  Downloading mediapipe-0.9.0.1-cp38-cp38-macosx_10_15_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe-model-maker) (1.19.2)\n",
      "Collecting opencv-python (from mediapipe-model-maker)\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow>=2.10 (from mediapipe-model-maker)\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-macosx_10_15_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-datasets (from mediapipe-model-maker)\n",
      "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting tensorflow-hub (from mediapipe-model-maker)\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tf-models-official>=2.10.1 (from mediapipe-model-maker)\n",
      "  Downloading tf_models_official-2.16.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe==0.9.0.1->mediapipe-model-maker) (20.3.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe==0.9.0.1->mediapipe-model-maker) (24.3.25)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe==0.9.0.1->mediapipe-model-maker) (3.3.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe==0.9.0.1->mediapipe-model-maker) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /opt/anaconda3/lib/python3.8/site-packages (from mediapipe==0.9.0.1->mediapipe-model-maker) (3.20.3)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.10->mediapipe-model-maker) (2.10.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting numpy (from mediapipe-model-maker)\n",
      "  Downloading numpy-1.24.3-cp38-cp38-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.10->mediapipe-model-maker) (20.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.10->mediapipe-model-maker) (50.3.1.post20201107)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.15.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow>=2.10->mediapipe-model-maker) (1.11.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading grpcio-1.62.1-cp38-cp38-macosx_10_10_universal2.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Cython in /opt/anaconda3/lib/python3.8/site-packages (from tf-models-official>=2.10.1->mediapipe-model-maker) (0.29.21)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.8/site-packages (from tf-models-official>=2.10.1->mediapipe-model-maker) (8.0.1)\n",
      "Collecting gin-config (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-api-python-client>=1.6.7 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading google_api_python_client-2.125.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting immutabledict (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading kaggle-1.6.8.tar.gz (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m310.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting oauth2client (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opencv-python-headless (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /opt/anaconda3/lib/python3.8/site-packages (from tf-models-official>=2.10.1->mediapipe-model-maker) (1.1.3)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/anaconda3/lib/python3.8/site-packages (from tf-models-official>=2.10.1->mediapipe-model-maker) (5.7.2)\n",
      "Collecting py-cpuinfo>=3.3.0 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting pycocotools (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading pycocotools-2.0.7-cp38-cp38-macosx_10_9_universal2.whl.metadata (1.1 kB)\n",
      "Collecting pyyaml>=6.0.0 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting sacrebleu (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading sacrebleu-2.4.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m58.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from tf-models-official>=2.10.1->mediapipe-model-maker) (1.5.2)\n",
      "Collecting sentencepiece (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading sentencepiece-0.2.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting seqeval (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m322.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official>=2.10.1 (from mediapipe-model-maker)\n",
      "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.14.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.14.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.14.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tensorflow-text~=2.13.0 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading tensorflow_text-2.13.0-cp38-cp38-macosx_10_9_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting tf-slim>=1.1.0 (from tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting array-record (from tensorflow-datasets->mediapipe-model-maker)\n",
      "  Downloading array_record-0.4.0-py38-none-any.whl.metadata (502 bytes)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->mediapipe-model-maker) (7.1.2)\n",
      "Collecting dm-tree (from tensorflow-datasets->mediapipe-model-maker)\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-macosx_10_9_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath]>=0.9.0->tensorflow-datasets->mediapipe-model-maker)\n",
      "  Downloading etils-1.3.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting promise (from tensorflow-datasets->mediapipe-model-maker)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->mediapipe-model-maker) (2.24.0)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets->mediapipe-model-maker)\n",
      "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: toml in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->mediapipe-model-maker) (0.10.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from tensorflow-datasets->mediapipe-model-maker) (4.50.2)\n",
      "Collecting importlib-resources (from tensorflow-datasets->mediapipe-model-maker)\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=2.10->mediapipe-model-maker) (0.35.1)\n",
      "Requirement already satisfied: zipp in /opt/anaconda3/lib/python3.8/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->mediapipe-model-maker) (3.4.0)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading google_api_core-2.18.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting certifi>=2023.7.22 (from kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker) (2.8.1)\n",
      "Collecting python-slugify (from kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker) (1.25.11)\n",
      "Requirement already satisfied: bleach in /opt/anaconda3/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker) (3.2.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.22.0->tf-models-official>=2.10.1->mediapipe-model-maker) (2020.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow-datasets->mediapipe-model-maker) (2.10)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker) (1.0.1)\n",
      "Collecting absl-py (from mediapipe-model-maker)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub->mediapipe-model-maker)\n",
      "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe==0.9.0.1->mediapipe-model-maker) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe==0.9.0.1->mediapipe-model-maker) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->mediapipe==0.9.0.1->mediapipe-model-maker) (2.4.7)\n",
      "Collecting pyasn1>=0.1.7 (from oauth2client->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pyasn1-modules>=0.0.5 (from oauth2client->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa>=3.1.4 (from oauth2client->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting portalocker (from sacrebleu->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.10.1->mediapipe-model-maker) (2020.10.15)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.10.1->mediapipe-model-maker) (0.4.4)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.8/site-packages (from sacrebleu->tf-models-official>=2.10.1->mediapipe-model-maker) (4.6.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/anaconda3/lib/python3.8/site-packages (from seqeval->tf-models-official>=2.10.1->mediapipe-model-maker) (0.23.2)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets->mediapipe-model-maker)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.10.1->mediapipe-model-maker) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.10.1->mediapipe-model-maker) (2.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.8/site-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.10.1->mediapipe-model-maker)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.10->mediapipe-model-maker)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading mediapipe_model_maker-0.1.0.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m175.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading mediapipe-0.9.0.1-cp38-cp38-macosx_10_15_x86_64.whl (35.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m176.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m[32m7.2/35.2 MB\u001b[0m \u001b[31m200.0 kB/s\u001b[0m eta \u001b[36m0:02:21\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.13.1-cp38-cp38-macosx_10_15_x86_64.whl (216.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.3-cp38-cp38-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Downloading google_api_python_client-2.125.0-py2.py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp38-cp38-macosx_10_10_universal2.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading PyYAML-6.0.1-cp38-cp38-macosx_10_9_x86_64.whl (191 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.7/191.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dm_tree-0.1.8-cp38-cp38-macosx_10_9_x86_64.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_text-2.13.0-cp38-cp38-macosx_10_9_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Downloading array_record-0.4.0-py38-none-any.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycocotools-2.0.7-cp38-cp38-macosx_10_9_universal2.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.8/168.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.1-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp38-cp38-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Downloading google_api_core-2.18.0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle, promise, seqeval\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.8-py3-none-any.whl size=111972 sha256=702728f230a9acc5d379e9caf869faf7cce51b4af76aa980fa51e5552b69bda7\n",
      "  Stored in directory: /Users/prathamgupta/Library/Caches/pip/wheels/b1/40/c7/202312cfc02c2ce70d16b537f0718dbfae9262b0466d6d9b25\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=eb410720f7c5c03df9d9a51b59f158a11b5c803ac107593299eba1670b771318\n",
      "  Stored in directory: /Users/prathamgupta/Library/Caches/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=62007a7971c8b6b53f20a79c1a0fe482454f8116ce350b480d64aab8dd0d7711\n",
      "  Stored in directory: /Users/prathamgupta/Library/Caches/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "Successfully built kaggle promise seqeval\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: text-unidecode, sentencepiece, py-cpuinfo, libclang, gin-config, dm-tree, uritemplate, typing-extensions, tf-keras, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, pyyaml, python-slugify, pyasn1, proto-plus, promise, portalocker, oauthlib, numpy, keras, importlib-resources, importlib-metadata, immutabledict, httplib2, grpcio, googleapis-common-protos, google-pasta, gast, etils, certifi, cachetools, astunparse, absl-py, tf-slim, tensorflow-model-optimization, tensorflow-metadata, tensorflow-hub, sacrebleu, rsa, pyasn1-modules, opt-einsum, opencv-python-headless, opencv-python, markdown, requests-oauthlib, pycocotools, oauth2client, mediapipe, kaggle, google-auth, seqeval, google-auth-oauthlib, google-auth-httplib2, google-api-core, array-record, tensorflow-datasets, tensorboard, google-api-python-client, tensorflow, tensorflow-text, tf-models-official, mediapipe-model-maker\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 5.3.1\n",
      "\u001b[31mERROR: Cannot uninstall 'PyYAML'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install mediapipe-model-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f165fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | ^C\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "CondaError: KeyboardInterrupt\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d06b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# assert tf.__version__.startswith('2')\n",
    "\n",
    "from mediapipe_model_maker import text_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/prathamgupta/Desktop/trainingLabeled.csv\"\n",
    "data_dir = os.path.join(os.path.dirname(data_path), 'trainingLabeled')  # folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddbfd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_params = text_classifier.CSVParams(\n",
    "    text_column='Lyrics', label_column='Label', delimiter='\\n')\n",
    "train_data = text_classifier.Dataset.from_csv(\n",
    "    filename=os.path.join(os.path.join(data_dir, 'train.tsv')),\n",
    "    csv_params=csv_params)\n",
    "validation_data = text_classifier.Dataset.from_csv(\n",
    "    filename=os.path.join(os.path.join(data_dir, 'dev.tsv')),\n",
    "    csv_params=csv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bcd6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_model = text_classifier.SupportedModels.MOBILEBERT_CLASSIFIER\n",
    "hparams = text_classifier.BertHParams(epochs=2, batch_size=48, learning_rate=3e-5, export_dir=\"bert_exported_models\")\n",
    "options = text_classifier.TextClassifierOptions(supported_model=supported_model, hparams=hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = text_classifier.TextClassifier.create(train_data, validation_data, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5822e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = bert_model.evaluate(validation_data)\n",
    "print(f'Test loss:{metrics[0]}, Test accuracy:{metrics[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8bd7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mediapipe_model_maker import quantization\n",
    "# quantization_config = quantization.QuantizationConfig.for_dynamic()\n",
    "# bert_model.export_model(quantization_config=quantization_config)\n",
    "# bert_model.export_labels(export_dir=options.hparams.export_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
